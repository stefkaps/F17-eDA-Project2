---
title: "Prediction of Parkinson's Disease"
author: 'Group 2: Kelly Jennings, Marcus Martinez, Changyong Yi, Rachel Tarrant, Stefanos
  Kapetanakis'
resource_files:
- .Renviron
output:
  html_notebook:
    code_folding: hide
    toc: yes
    toc_depth: 4
    toc_float: yes
runtime: shiny
---

```{r setup, include=FALSE}
library(tidyverse)
require(MASS)
require(ggplot2)
require(ISLR)
require(shiny)
require(data.world)
knitr::opts_chunk$set(echo = TRUE)
```
  
## **R Session Info**  

```{r}
sessionInfo()
```

## **Github Link** 
https://github.com/stefkaps/F17-eDA-Project2

## **Connecting to data.world** 
```{r}
project <- "https://data.world/marcusgabe-ut/parkinsons-data"
data.world::set_config(cfg_env("DW_API"))
df <- data.world::query(
 data.world::qry_sql("SELECT * FROM parkinsons"),
 dataset = project
)
```

## Setup

```{r}
attach(df)
df = df %>% dplyr::mutate(status2 = ifelse(status == "true", 1, 0))
```


## **Introduction** 
This dataset is composed of a range of biomedical voice measurements from 31 people, 23 with Parkinson's disease (PD). Each column in the table is a particular voice measure, and each row corresponds one of 195 voice recording from these individuals ("name" column). The main aim of the data is to discriminate healthy people from those with PD, according to "status" column which is set to 0 or false for healthy and 1 or true for PD.


Attribute Information:

Matrix column entries (attributes):

name - ASCII subject name and recording number

MDVP:Fo(Hz) - Average vocal fundamental frequency

MDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several measures of variation in fundamental frequency

MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude

status - Health status of the subject (one/true) - Parkinson's, (zero/false) - healthy

This document will provide readers four different types of analysis: Logistic Regression, Linear Discriminant Analysis, Quadratic Discriminant Analysis, and K-Nearest Neighbors. 

## Logistic Regression
This 

```{r}
train = sample(nrow(df), 97)
test = df[-train,]

glm1.fit=glm(status2 ~ mdvp_fo_hz + mdvp_jitter,
             data=df, family=binomial,
             subset=train)
summary(glm1.fit)
glm1.probs=predict(glm1.fit,newdata=test,type="response")
#glm1.probs[1:5]
glm1.pred=ifelse(glm1.probs>0.5,"1","0")
status2.test = test$status2
table(glm1.pred,status2.test)
mean(glm1.pred==status2.test)
```

This

```{r}
glm3.fit=glm(status2 ~ mdvp_fo_hz + mdvp_jitter + rpde + d2 + dfa + spread1,
             data=df, family=binomial,
             subset=train)
summary(glm3.fit)
glm3.probs=predict(glm3.fit,newdata=test,type="response")
#glm.probs[1:5]
glm3.pred=ifelse(glm3.probs>0.5,"1","0")
status2.test = test$status2
table(glm3.pred,status2.test)
mean(glm3.pred==status2.test)

```


## Linear Discriminant Analysis
```{r}
lda1.fit=lda(status ~ mdvp_fo_hz + mdvp_jitter,
             data=df, subset=train)
lda1.fit

lda1.pred=predict(lda1.fit, test)
lda1_df = data.frame(lda1.pred)

table(lda1.pred$class,test$status)
table(lda1.pred$class==test$status)
table(lda1.pred$class!=test$status)
mean(lda1.pred$class==test$status)
```

```{r}
#LDA plots
renderPlot(plot(lda1.fit))
renderPlot({ggplot(lda1_df) + geom_histogram(mapping=aes(x=LD1))})
renderPlot({ggplot(lda1_df) + geom_boxplot(mapping = aes(x=class,y=LD1))})
```

```{r}
lda3.fit=lda(status ~ mdvp_fo_hz + mdvp_jitter + rpde + d2 + dfa + spread1,
             data=df, subset=train)
lda3.fit

lda3.pred=predict(lda3.fit, test)
lda3_df = data.frame(lda3.pred)
ggplot(lda3_df) + geom_histogram(mapping=aes(x=LD1))
ggplot(lda3_df) + geom_boxplot(mapping = aes(x=class,y=LD1))
table(lda3.pred$class,test$status)
table(lda3.pred$class==test$status)
table(lda3.pred$class!=test$status)
mean(lda3.pred$class==test$status)
```

```{r}
renderPlot(plot(lda3.fit))
```




## Quadratic Discriminant Analysis

```{r}
qda1.fit = qda(status ~ mdvp_fo_hz + mdvp_jitter,
              data=df, subset=train)
qda1.fit
qda1.pred = predict(qda1.fit, test)
table(qda1.pred$class,test$status)
table(qda1.pred$class==test$status)
table(qda1.pred$class!=test$status)
mean(qda1.pred$class==test$status)
```

```{r}
qda.fit3 = qda(status ~ mdvp_fo_hz + mdvp_jitter + rpde + d2 + dfa + spread1,
               data=df, subset=train)
qda.fit3
qda.pred3 = predict(qda.fit3, test)
table(qda.pred3$class,test$status)
table(qda.pred3$class==test$status)
table(qda.pred3$class!=test$status)
mean(qda.pred3$class==test$status)
```


## K-Nearest Neighbors

```{r}
test_knn = sample(nrow(test), 97)
predictors1=cbind(mdvp_fo_hz, mdvp_jitter)
knn1.pred=class::knn(predictors1[train, ],predictors1[test_knn,],status[train],k=1)
table(knn1.pred,status[test_knn])
mean(knn1.pred==status[test_knn])

```

```{r}
predictors3=cbind(mdvp_fo_hz, mdvp_jitter, rpde, d2, dfa, spread1)
knn3.pred=class::knn(predictors3[train, ],predictors3[test_knn,],status[train],k=1)
table(knn3.pred,status[test_knn])
mean(knn3.pred==status[test_knn])

```


## Comparison of the Mean Correct Predictions


```{r}
# Comparison of the mean correct predictions
mean(glm1.pred==status2.test)
mean(glm3.pred==status2.test)
mean(lda1.pred$class==test$status)
mean(lda3.pred$class==test$status)
mean(qda1.pred$class==test$status)
mean(qda.pred3$class==test$status)
mean(knn1.pred==status[test_knn])
mean(knn3.pred==status[test_knn])


```

## Insights


