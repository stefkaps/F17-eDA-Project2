---
title: "Prediction of Parkinson's Disease"
author: 'Group 2: Kelly Jennings, Marcus Martinez, Changyong Yi, Rachel Tarrant, Stefanos
  Kapetanakis'
resource_files:
- .Renviron
output:
  html_notebook:
    code_folding: hide
    toc: yes
    toc_depth: 4
    toc_float: yes
runtime: shiny
---

```{r setup, include=FALSE}
library(tidyverse)
require(MASS)
require(ggplot2)
require(ISLR)
require(shiny)
require(data.world)
knitr::opts_chunk$set(echo = TRUE)
```
  
## **R Session Info**  

```{r}
sessionInfo()
```

## **Github Link** 
https://github.com/stefkaps/F17-eDA-Project2

## **Connecting to data.world** 
```{r}
project <- "https://data.world/marcusgabe-ut/parkinsons-data"
data.world::set_config(cfg_env("DW_API"))
df <- data.world::query(
 data.world::qry_sql("SELECT * FROM parkinsons"),
 dataset = project
)
```

## Setup
In the setup, we randomly split the dataset into two halves, one used for training the model, and the other for testing the model. We also added a column to the dataset to translate the boolean strings to binary values.

```{r}
attach(df)
df = df %>% dplyr::mutate(status2 = ifelse(status == "true", 1, 0))
train = sample(nrow(df), 97)
test = df[-train,]
set.seed(1)
```


## **Introduction** 
This dataset is composed of a range of biomedical voice measurements from 31 people, 23 with Parkinson's disease (PD). Each column in the table is a particular voice measure, and each row corresponds one of 195 voice recording from these individuals ("name" column). The main aim of the data is to discriminate healthy people from those with PD, according to "status" column which is set to 0 or false for healthy and 1 or true for PD.


Partial Attribute Information (to view the complete list of attributes, visit the data.world link):

Matrix column entries (attributes):

name - ASCII subject name and recording number

MDVP:Fo(Hz) - Average vocal fundamental frequency

MDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several measures of variation in fundamental frequency

MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude

status - Health status of the subject (one/true) - Parkinson's, (zero/false) - healthy

RPDE,D2 - Two nonlinear dynamical complexity measures

DFA - Signal fractal scaling exponent

spread1,spread2,PPE - Three nonlinear measures of fundamental frequency variation

This document will provide readers four different types of analysis: Logistic Regression, Linear Discriminant Analysis, Quadratic Discriminant Analysis, and K-Nearest Neighbors. 

## Logistic Regression
For both of the following models we utilized a probability threshold of 0.5.


Here we are analyzing two predictors, average hertz and jitter, to predict the Parkinson's Disease status of the patient. We are using Logistic Regression to analyze the predictability of having Parkinson's Disease given these variables. 

```{r}
glm1.fit=glm(status2 ~ mdvp_fo_hz + mdvp_jitter,
             data=df, family=binomial,
             subset=train)
summary(glm1.fit)
glm1.probs=predict(glm1.fit,newdata=test,type="response")
#glm1.probs[1:5]
glm1.pred=ifelse(glm1.probs>0.5,"1","0")
status2.test = test$status2
table(glm1.pred,status2.test)
mean(glm1.pred==status2.test)
```


Here we are analyzing six predictors, average hertz, jitter, rpde, d2, dfa, and spread1 to predict the Parkinson's Disease status of the patient. We are using Logistic Regression to analyze the predictability of having Parkinson's Disease given these variables. 

```{r}
glm3.fit=glm(status2 ~ mdvp_fo_hz + mdvp_jitter + rpde + d2 + dfa + spread1,
             data=df, family=binomial,
             subset=train)
summary(glm3.fit)
glm3.probs=predict(glm3.fit,newdata=test,type="response")
#glm.probs[1:5]
glm3.pred=ifelse(glm3.probs>0.5,"1","0")
status2.test = test$status2
table(glm3.pred,status2.test)
mean(glm3.pred==status2.test)

```


## Linear Discriminant Analysis


Here we are analyzing two predictors, average hertz and jitter, to predict the Parkinson's Disease status of the patient. We are using Linear Discriminant Analysis to analyze the predictability of having Parkinson's Disease given these variables. 

```{r}
lda1.fit=lda(status ~ mdvp_fo_hz + mdvp_jitter,
             data=df, subset=train)
lda1.fit

lda1.pred=predict(lda1.fit, test)
lda1_df = data.frame(lda1.pred)

table(lda1.pred$class,test$status)
table(lda1.pred$class==test$status)
table(lda1.pred$class!=test$status)
mean(lda1.pred$class==test$status)
```


The following are visual representations of the probabilities calculated by the Linear Discriminant Analysis.

```{r}
#LDA plots
renderPlot(plot(lda1.fit))
renderPlot({ggplot(lda1_df) + geom_histogram(mapping=aes(x=LD1))})
renderPlot({ggplot(lda1_df) + geom_boxplot(mapping = aes(x=class,y=LD1))})
```


Here we are analyzing six predictors, average hertz, jitter, rpde, d2, dfa, and spread1 to predict the Parkinson's Disease status of the patient. We are using Linear Discriminant Analysis to analyze the predictability of having Parkinson's Disease given these variables. 

```{r}
lda3.fit=lda(status ~ mdvp_fo_hz + mdvp_jitter + rpde + d2 + dfa + spread1,
             data=df, subset=train)
lda3.fit

lda3.pred=predict(lda3.fit, test)
lda3_df = data.frame(lda3.pred)
table(lda3.pred$class,test$status)
table(lda3.pred$class==test$status)
table(lda3.pred$class!=test$status)
mean(lda3.pred$class==test$status)
```


The following are the same types of visual representations of the probabilities calculated by the Linear Discriminant Analysis, using six predictors.

```{r}
renderPlot(plot(lda3.fit))
renderPlot({ggplot(lda3_df) + geom_histogram(mapping=aes(x=LD1))})
renderPlot({ggplot(lda3_df) + geom_boxplot(mapping = aes(x=class,y=LD1))})
```




## Quadratic Discriminant Analysis


Here we are analyzing two predictors, average hertz and jitter, to predict the Parkinson's Disease status of the patient. We are using Quadratic Discriminant Analysis to analyze the predictability of having Parkinson's Disease given these variables. 

```{r}
qda1.fit = qda(status ~ mdvp_fo_hz + mdvp_jitter,
              data=df, subset=train)
qda1.fit
qda1.pred = predict(qda1.fit, test)
table(qda1.pred$class,test$status)
table(qda1.pred$class==test$status)
table(qda1.pred$class!=test$status)
mean(qda1.pred$class==test$status)
```


Here we are analyzing six predictors, average hertz, jitter, rpde, d2, dfa, and spread1 to predict the Parkinson's Disease status of the patient. We are using Quadratic Discriminant Analysis to analyze the predictability of having Parkinson's Disease given these variables.  

```{r}
qda.fit3 = qda(status ~ mdvp_fo_hz + mdvp_jitter + rpde + d2 + dfa + spread1,
               data=df, subset=train)
qda.fit3
qda.pred3 = predict(qda.fit3, test)
table(qda.pred3$class,test$status)
table(qda.pred3$class==test$status)
table(qda.pred3$class!=test$status)
mean(qda.pred3$class==test$status)
```


## K-Nearest Neighbors

Here we are analyzing two predictors, average hertz and jitter, to predict the Parkinson's Disease status of the patient. We are using K-Nearest Neighbors to analyze the predictability of having Parkinson's Disease given these variables.

```{r}
test_knn = sample(nrow(test), 97)
predictors1=cbind(mdvp_fo_hz, mdvp_jitter)
knn1.pred=class::knn(predictors1[train, ],predictors1[test_knn,],status[train],k=1)
table(knn1.pred,status[test_knn])
mean(knn1.pred==status[test_knn])

```


Here we are analyzing six predictors, average hertz, jitter, rpde, d2, dfa, and spread1 to predict the Parkinson's Disease status of the patient. We are using K-Nearest Neighbors to analyze the predictability of having Parkinson's Disease given these variables. 

```{r}
predictors3=cbind(mdvp_fo_hz, mdvp_jitter, rpde, d2, dfa, spread1)
knn3.pred=class::knn(predictors3[train, ],predictors3[test_knn,],status[train],k=1)
table(knn3.pred,status[test_knn])
mean(knn3.pred==status[test_knn])

```


## Comparison of the Mean Correct Predictions


The following is a list of all the mean correct predictions for each of the models. For each type of analysis, the first mean represents the two predictor models and the second represents the six predictor models.

Logictic Regressions Results
```{r}
mean(glm1.pred==status2.test)
mean(glm3.pred==status2.test)

```

Linear Discriminant Analysis Results
```{r}
mean(lda1.pred$class==test$status)
mean(lda3.pred$class==test$status)
```

Quadratic Discriminant Analysis Results
```{r}
mean(qda1.pred$class==test$status)
mean(qda.pred3$class==test$status)
```

K-Nearest Neighbors Results
```{r}
mean(knn1.pred==status[test_knn])
mean(knn3.pred==status[test_knn])
```




## Research Progression

Using the pairs function we found predictors that aren't confounding and chose these to analyze. Initially we decided to choose average hertz and jitter, as our predictors, because they yielded the best results among the two predictor combinations. The six predictors models were better predictors overall. The means were consistantly better than the two predictor models throughout our data exploration. 


##Insights

When analyzing each model, the greater mean for each analysis type was not consistant (i.e. neither the two nor six predictor model proved to be better). However, despite these inconsistancies, the differences between each model within each analysis were small. These inconsistancies were a consequence of random sampling, as well as our data being relatively small. Our worst models still yielded relatively good results usually above .75 for both two and six predictor models.

Even though these inconsistancies were present, the K-Nearest Neighbors (KNN) analysis type yields the overall best results. In fact, the six predictor model within the KNN analysis typically had the highest mean. The usual mean percentage was around .91 to .96.

Parkinson's Disease is associated with a certain speech pattern; because our predictors are measurements of the patients' speech pattern, it is unsurprising that even our worst models had high prediction rates. 


